{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Reconstruct Anything Model (RAM) for solving inverse problems.\n\nThis example shows how to use the RAM foundation model to solve inverse problems. The RAM model, described in\nthe following [paper](https://arxiv.org/abs/2503.08915), is a modified DRUNet architecture that is trained on\na large number of inverse problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport deepinv as dinv\nfrom deepinv.models import RAM\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load the pretrained model\nmodel = RAM(device=device)\n\n# load image\nx = dinv.utils.load_example(\"butterfly.png\", img_size=(127, 129)).to(device)\n\n# create forward operator\nphysics = dinv.physics.Inpainting(\n    img_size=(3, 127, 129),\n    mask=0.3,\n    noise_model=dinv.physics.GaussianNoise(0.05),\n    device=device,\n)\n\n# generate measurement\ny = physics(x)\n\n# run inference\nwith torch.no_grad():\n    x_hat = model(y, physics=physics)\n\n# compute PSNR\nin_psnr = dinv.metric.PSNR()(x, y).item()\nout_psnr = dinv.metric.PSNR()(x, x_hat).item()\n\n# plot\ndinv.utils.plot(\n    [x, y, x_hat],\n    [\n        \"Original\",\n        \"Measurement\\n PSNR = {:.2f}dB\".format(in_psnr),\n        \"Reconstruction\\n PSNR = {:.2f}dB\".format(out_psnr),\n    ],\n    figsize=(8, 3),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model was also trained on various denoising problems, in particular on Poisson-Gaussian denoising.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigma, gain = 0.2, 0.5\nphysics = dinv.physics.Denoising(\n    noise_model=dinv.physics.PoissonGaussianNoise(sigma=sigma, gain=gain),\n)\n\n# generate measurement\ny = physics(x)\n\n# run inference\nwith torch.no_grad():\n    x_hat = model(y, physics=physics)\n    # or alternatively, we can use the model without physics:\n    # x_hat = model(y, sigma=sigma, gain=gain)\n\n# compute PSNR\nin_psnr = dinv.metric.PSNR()(x, y).item()\nout_psnr = dinv.metric.PSNR()(x, x_hat).item()\n\n# plot\ndinv.utils.plot(\n    [x, y, x_hat],\n    [\n        \"Original\",\n        \"Measurement\\n PSNR = {:.2f}dB\".format(in_psnr),\n        \"Reconstruction\\n PSNR = {:.2f}dB\".format(out_psnr),\n    ],\n    figsize=(8, 3),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model is not trained on all degradations, so it may not perform well on all inverse problems out-of-the-box.\nFor instance, it is not trained on image demosaicing. Applying it to a demosaicing problem out-of-the-box will yield poor results,\nas shown in the following example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the Demosaicing physics\nphysics = dinv.physics.Demosaicing(\n    img_size=x.shape[1:], noise_model=dinv.physics.PoissonNoise(0.1), device=device\n)\n\n# generate measurement\ny = physics(x)\n\n# run inference\nwith torch.no_grad():\n    x_hat = model(y, physics=physics)\n\n# compute PSNR\nin_psnr = dinv.metric.PSNR()(x, y).item()\nout_psnr = dinv.metric.PSNR()(x, x_hat).item()\n\n# plot\ndinv.utils.plot(\n    [x, y, x_hat],\n    [\n        \"Original\",\n        \"Measurement\\n PSNR = {:.2f}dB\".format(in_psnr),\n        \"0 shot reconstruction\\n PSNR = {:.2f}dB\".format(out_psnr),\n    ],\n    figsize=(8, 3),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To improve results, we can fine-tune the model on the specific degradation for the sample of interest.\nThis can be done even in the absence of ground truth data, using unsupervised training.\nWe showcase this in the following, where the model is fine-tuned on the measurement vector `y` itself.\nHere, since this example is run in a no-GPU environment, we will use a small patch of the image to speed up training,\nbut in practice, we can use the full image.\n\nFirst, we will create a dataset for unsupervised training that\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class UnsupDataset(torch.utils.data.Dataset):\n    r\"\"\"\n    Dataset for unsupervised learning tasks.\n\n    This dataset is used to return only the data without any labels.\n\n    :param torch.Tensor data: Input data tensor of shape (N, ...), where N is the number of samples and ... represents the data dimensions.\n    \"\"\"\n\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return self.data.size(0)\n\n    def __getitem__(self, idx):\n        return torch.nan, self.data[idx]\n\n\nphysics_train = dinv.physics.Demosaicing(\n    img_size=(3, 64, 64),\n    noise_model=dinv.physics.PoissonNoise(0.1, clip_positive=True),\n    device=device,\n)\nx_train = x[..., :64, :64]  # take a small patch of the image\ny_train = physics_train(x_train)\n\nlosses = [\n    dinv.loss.R2RLoss(),\n    dinv.loss.EILoss(dinv.transform.Shift(shift_max=0.4), weight=0.1),\n]\n\ndataset = UnsupDataset(y_train)\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to check the performance of the fine-tuned model, we will use a validation set.\nWe will use a small patch of another image. Note that this validation is also performed in an unsupervised manner,\nso we will not use the ground truth validation image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_val = physics_train(dinv.utils.load_example(\"leaves.png\")[..., :64, :64].to(device))\neval_dataloader = torch.utils.data.DataLoader(UnsupDataset(y_val))\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n\nmax_epochs = 20\ntrainer = dinv.Trainer(\n    model=model,\n    physics=physics_train,\n    eval_interval=5,\n    ckp_interval=max_epochs - 1,\n    metrics=losses[0],\n    early_stop=True,\n    device=device,\n    losses=losses,\n    epochs=max_epochs,\n    optimizer=optimizer,\n    train_dataloader=train_dataloader,\n    eval_dataloader=eval_dataloader,\n)\n\n# finetune\nfinetuned_model = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the fine-tuned model to reconstruct the image from the measurement vector `y`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n    x_hat = finetuned_model(y, physics=physics)\n\n# compute PSNR\nin_psnr = dinv.metric.PSNR()(x, y).item()\nout_psnr = dinv.metric.PSNR()(x, x_hat).item()\n\n# plot\ndinv.utils.plot(\n    [x, y, x_hat],\n    [\n        \"Original\",\n        \"Measurement\\n PSNR = {:.2f}dB\".format(in_psnr),\n        \"Finetuned reconstruction\\n PSNR = {:.2f}dB\".format(out_psnr),\n    ],\n    figsize=(8, 3),\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}